{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans # This package is here to implement kmeans clustering, used to generate radial basis functions \n",
    "import numpy as np # This package is used to perform mathematical operations as well as storing and manipulating multi-demnsional arrays and matrices\n",
    "import csv # This package is used to read and write csv files\n",
    "import math # This package is used to perform mathematical operations\n",
    "from matplotlib import pyplot as plt # The matplotlib package is used for plotting graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAcc = 0.0\n",
    "maxIter = 0\n",
    "\n",
    "# Regularization parameter\n",
    "C_lambda = [0, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]\n",
    "\n",
    "# Perncentage of data to be taken for training, validation and testing\n",
    "TrainingPercent = 80\n",
    "ValidationPercent = 10\n",
    "TestPercent = 10\n",
    "\n",
    "# Number of cluster centers, used while generating radial basis functions\n",
    "M = [1, 5, 10, 50 , 100, 200, 400]\n",
    "\n",
    "# List to store M basis function\n",
    "PHI = []\n",
    "\n",
    "IsSynthetic = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read target vector from csv file with given filename, and return as list\n",
    "def GetTargetVector(filePath):\n",
    "    t = []\n",
    "    with open(filePath, 'rU') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:  \n",
    "            t.append(int(row[0]))\n",
    "    #print(\"Raw Training Generated..\")\n",
    "    return t\n",
    "\n",
    "# Function to read input data vector from csv file with given filename, and return as list\n",
    "def GenerateRawData(filePath, IsSynthetic):    \n",
    "    dataMatrix = [] \n",
    "    with open(filePath, 'rU') as fi:\n",
    "        reader = csv.reader(fi)\n",
    "        \n",
    "        # Each element in the csv file read and appended with the dataMatrix list\n",
    "        for row in reader:\n",
    "            dataRow = []\n",
    "            for column in row:\n",
    "                dataRow.append(float(column))\n",
    "            dataMatrix.append(dataRow)   \n",
    "    \n",
    "    if IsSynthetic == False :\n",
    "        dataMatrix = np.delete(dataMatrix, [5,6,7,8,9], axis=1)\n",
    "    dataMatrix = np.transpose(dataMatrix)     \n",
    "    #print (\"Data Matrix Generated..\")\n",
    "    return dataMatrix\n",
    "\n",
    "# From the raw data read from the file, generate training target by taking the first 80% of samples\n",
    "def GenerateTrainingTarget(rawTraining,TrainingPercent = 80):\n",
    "    TrainingLen = int(math.ceil(len(rawTraining)*(TrainingPercent*0.01)))\n",
    "    t           = rawTraining[:TrainingLen]\n",
    "    #print(str(TrainingPercent) + \"% Training Target Generated..\")\n",
    "    return t\n",
    "\n",
    "# From the raw data read from the file, generate training input data by taking the first 80% of samples\n",
    "def GenerateTrainingDataMatrix(rawData, TrainingPercent = 80):\n",
    "    T_len = int(math.ceil(len(rawData[0])*0.01*TrainingPercent))\n",
    "    d2 = rawData[:,0:T_len]\n",
    "    #print(str(TrainingPercent) + \"% Training Data Generated..\")\n",
    "    return d2\n",
    "\n",
    "# From the raw data read from the file, generate validation input data by taking the the next 10% (after training samples) of samples\n",
    "#  Here training count is also specified, so the function can select samples after the training data\n",
    "def GenerateValData(rawData, ValPercent, TrainingCount): \n",
    "    valSize = int(math.ceil(len(rawData[0])*ValPercent*0.01))\n",
    "    V_End = TrainingCount + valSize\n",
    "    dataMatrix = rawData[:,TrainingCount+1:V_End]\n",
    "    #print (str(ValPercent) + \"% Val Data Generated..\")  \n",
    "    return dataMatrix\n",
    "\n",
    "# From the raw data read from the file, generate validation target by taking the the next 10% (after training samples) of samples\n",
    "def GenerateValTargetVector(rawData, ValPercent, TrainingCount): \n",
    "    valSize = int(math.ceil(len(rawData)*ValPercent*0.01))\n",
    "    V_End = TrainingCount + valSize\n",
    "    t =rawData[TrainingCount+1:V_End]\n",
    "    #print (str(ValPercent) + \"% Val Target Data Generated..\")\n",
    "    return t\n",
    "\n",
    "# Function to generate big sigma, which is a measure of how the input data spreads for each feature in the dataset\n",
    "def GenerateBigSigma(Data, MuMatrix,TrainingPercent,IsSynthetic):\n",
    "    \n",
    "    #  Create empty matrix of size (f,f) where f is number of features in dataset    \n",
    "    BigSigma    = np.zeros((len(Data),len(Data)))\n",
    "    \n",
    "    # Since data is of form (fxn), it is transposed here to (nxf)\n",
    "    DataT       = np.transpose(Data)\n",
    "   \n",
    "    # Ensures that variance is calculated only on 80% of input data used for training \n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))        \n",
    "    varVect     = []\n",
    "    \n",
    "    # Calculate variance for each of 41 features\n",
    "    for i in range(0,len(DataT[0])):\n",
    "        vct = []\n",
    "        for j in range(0,int(TrainingLen)):\n",
    "            vct.append(Data[i][j])    \n",
    "        varVect.append(np.var(vct))\n",
    "    \n",
    "    # The variances computed in the previous step are used to generate the (fxf) diagonal matrix big sigma\n",
    "    for j in range(len(Data)):\n",
    "        BigSigma[j][j] = varVect[j]\n",
    "        \n",
    "    # Value of big sigma multiplied with a large number to ensure its value stays significant\n",
    "    if IsSynthetic == True:\n",
    "        BigSigma = np.dot(3,BigSigma)\n",
    "    else:\n",
    "        BigSigma = np.dot(200,BigSigma)\n",
    "    ##print (\"BigSigma Generated..\")\n",
    "    return BigSigma\n",
    "\n",
    "# This function does (x-mu)*(sigma^-1)(s-mu), where x is a single row from the data set and mu is one of the M cluster centroids and sigma^-1 is matrix inverse of big sigma\n",
    "def GetScalar(DataRow,MuRow, BigSigInv):  \n",
    "    R = np.subtract(DataRow,MuRow)\n",
    "    T = np.dot(BigSigInv,np.transpose(R))  \n",
    "    L = np.dot(R,T)\n",
    "    return L\n",
    "\n",
    "# Function to get e^(-0.5X), where X is the scalar value returned from the GetScalar function\n",
    "def GetRadialBasisOut(DataRow,MuRow, BigSigInv):    \n",
    "    phi_x = math.exp(-0.5*GetScalar(DataRow,MuRow,BigSigInv))\n",
    "    return phi_x\n",
    "\n",
    "# Function to generate the phi matrix, the matrix representation of the values of radial basis functions of the input with M centroids,\n",
    "# which will be used to train the parameters in linear regression. RBFs are used to introduce non-linearity in the model.\n",
    "def GetPhiMatrix(Data, MuMatrix, BigSigma, TrainingPercent = 80):\n",
    "    \n",
    "    # Since data is of form (fxn), it is transposed here to (nxf)\n",
    "    DataT = np.transpose(Data)\n",
    "    \n",
    "    # Initialize phi matrix with size (nxM) with the set training length\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))         \n",
    "    PHI = np.zeros((int(TrainingLen),len(MuMatrix))) \n",
    "    \n",
    "    # Get matrix inverse of big sigma\n",
    "    BigSigInv = np.linalg.inv(BigSigma)\n",
    "    \n",
    "    # Calculate value of the radial basis function for each sample in the input data set with each M centroid, for the big sigma calculated\n",
    "    for  C in range(0,len(MuMatrix)):\n",
    "        for R in range(0,int(TrainingLen)):\n",
    "            PHI[R][C] = GetRadialBasisOut(DataT[R], MuMatrix[C], BigSigInv)\n",
    "    #print (\"PHI Generated..\")\n",
    "    return PHI\n",
    "\n",
    "# Function to get weights or parameters in the linear regression model using a closed form solution. i.e using linear algebra\n",
    "# to solve the equations mathematically and arrive at the soution\n",
    "def GetWeightsClosedForm(PHI, T, Lambda):\n",
    "    \n",
    "    # Create MxM lambda matrix, this will be used for regulirization\n",
    "    Lambda_I = Lambda*np.identity(len(PHI[0]))\n",
    "    \n",
    "    # Initialize lambda matrix to lambda, the regulirization paramter, using a MxM diagonal matrix,\n",
    "    # this is required while computing weights with regulirization\n",
    "#     for i in range(0,len(PHI[0])):\n",
    "#         Lambda_I[i][i] = Lambda\n",
    "    \n",
    "    # The following lines implement the following equation,\n",
    "    # w=((lambda*I + phi'*phi)^-1)*phi' *targetVector, where phi' is transpose of phi\n",
    "    PHI_T       = np.transpose(PHI)\n",
    "    PHI_SQR     = np.dot(PHI_T,PHI)\n",
    "    PHI_SQR_LI  = np.add(Lambda_I,PHI_SQR)\n",
    "    PHI_SQR_INV = np.linalg.inv(PHI_SQR_LI)\n",
    "    INTER       = np.dot(PHI_SQR_INV, PHI_T)\n",
    "    W           = np.dot(INTER, T)\n",
    "    ##print (\"Training Weights Generated..\")\n",
    "    return W\n",
    "\n",
    "# Predicts values of output labels for validation set based on the parameters learnt\n",
    "def GetValTest(VAL_PHI,W):\n",
    "    Y = np.dot(W,np.transpose(VAL_PHI))\n",
    "    ##print (\"Test Out Generated..\")\n",
    "    return Y\n",
    "\n",
    "# Function to compute performance of the model for given training/validation/test predicted labels and their corresponding targets\n",
    "def GetErms(VAL_TEST_OUT,ValDataAct):\n",
    "    sum = 0.0\n",
    "    t=0\n",
    "    accuracy = 0.0\n",
    "    counter = 0\n",
    "    val = 0.0\n",
    "    for i in range (0,len(VAL_TEST_OUT)):\n",
    "        \n",
    "        # Computing sum of squared differences, between target and predicted label\n",
    "        sum = sum + math.pow((ValDataAct[i] - VAL_TEST_OUT[i]),2)\n",
    "        \n",
    "        # Checking if rounded predicted value is same as target value, and if so count it\n",
    "        if(int(np.around(VAL_TEST_OUT[i], 0)) == ValDataAct[i]):\n",
    "            counter+=1\n",
    "    # Percentage of total number of correct predictions over total predictions\n",
    "    accuracy = (float((counter*100))/float(len(VAL_TEST_OUT)))\n",
    "    ##print (\"Accuracy Generated..\")\n",
    "    ##print (\"Validation E_RMS : \" + str(math.sqrt(sum/len(VAL_TEST_OUT))))\n",
    "    return (str(accuracy) + ',' +  str(math.sqrt(sum/len(VAL_TEST_OUT))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: 'U' mode is deprecated\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Dan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: 'U' mode is deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Function calls to read target labels and input data\n",
    "RawTarget = GetTargetVector('Querylevelnorm_t.csv')\n",
    "RawData   = GenerateRawData('Querylevelnorm_X.csv',IsSynthetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55699,)\n",
      "(41, 55699)\n"
     ]
    }
   ],
   "source": [
    "# Function calls to generate training target labels and training inpupt data\n",
    "TrainingTarget = np.array(GenerateTrainingTarget(RawTarget,TrainingPercent))\n",
    "TrainingData   = GenerateTrainingDataMatrix(RawData,TrainingPercent)\n",
    "print(TrainingTarget.shape)\n",
    "print(TrainingData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6962,)\n",
      "(41, 6962)\n"
     ]
    }
   ],
   "source": [
    "# Function calls to generate validation target labels and validation inpupt data\n",
    "ValDataAct = np.array(GenerateValTargetVector(RawTarget,ValidationPercent, (len(TrainingTarget))))\n",
    "ValData    = GenerateValData(RawData,ValidationPercent, (len(TrainingTarget)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6962,)\n",
      "(41, 6962)\n"
     ]
    }
   ],
   "source": [
    "# Function calls to generate test target labels and test inpupt data\n",
    "TestDataAct = np.array(GenerateValTargetVector(RawTarget,TestPercent, (len(TrainingTarget)+len(ValDataAct))))\n",
    "TestData = GenerateValData(RawData,TestPercent, (len(TrainingTarget)+len(ValDataAct)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closed Form Solution [Finding Weights using Moore- Penrose pseudo- Inverse Matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErmsArr = []\n",
    "AccuracyArr = []\n",
    "\n",
    "# Lists to store data obtained for different hyper-parameter combinations\n",
    "trainingPHIList=[]\n",
    "validationPHIList=[]\n",
    "testPHIList=[]\n",
    "weightList=[]\n",
    "\n",
    "# Grid search for M and C_lambda to see which value of M and lambda work well for the model\n",
    "for m in M:\n",
    "    \n",
    "    # Use scikit learn's KMeans method to generate M cluster centroids, this will be used to generate the gaussian basis functions\n",
    "    kmeans = KMeans(n_clusters=m, random_state=0).fit(np.transpose(TrainingData))\n",
    "    Mu = kmeans.cluster_centers_\n",
    "    \n",
    "    # Use random points in feature space for Mu\n",
    "    #     idx = np.random.randint(len(TrainingData[0]), size=m)\n",
    "    #     Mu=np.transpose(np.array(TrainingData[:,idx]))\n",
    "    \n",
    "    # Function calls to generate big sigma, training/validation/test phi matrices for the regression model\n",
    "    BigSigma     = GenerateBigSigma(RawData, Mu, TrainingPercent,IsSynthetic)\n",
    "    TRAINING_PHI = GetPhiMatrix(RawData, Mu, BigSigma, TrainingPercent)\n",
    "    TEST_PHI     = GetPhiMatrix(TestData, Mu, BigSigma, 100) \n",
    "    VAL_PHI      = GetPhiMatrix(ValData, Mu, BigSigma, 100)\n",
    "    weightRows=[]\n",
    "    \n",
    "    for c_lambda in C_lambda:\n",
    "        \n",
    "            # Function call to generate learned weights for the regression model\n",
    "            weightRows.append(GetWeightsClosedForm(TRAINING_PHI,TrainingTarget,(c_lambda))) \n",
    "            \n",
    "    weightList.append(weightRows)   \n",
    "    trainingPHIList.append(TRAINING_PHI)\n",
    "    validationPHIList.append(VAL_PHI)\n",
    "    testPHIList.append(TEST_PHI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 41)\n",
      "(41, 41)\n",
      "(55699, 10)\n",
      "(10,)\n",
      "(6962, 10)\n",
      "(6961, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Mu.shape)\n",
    "print(BigSigma.shape)\n",
    "print(TRAINING_PHI.shape)\n",
    "print(W.shape)\n",
    "print(VAL_PHI.shape)\n",
    "print(TEST_PHI.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Erms on training, validation and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function calls to get predicted labels using the learned weights for each data set\n",
    "trainingAccuracyList=[]\n",
    "validationAccuracyList=[]\n",
    "testAccuracyList=[]\n",
    "\n",
    "\n",
    "for rowInd in range(len(M)):\n",
    "    trainingAccuracyListRow=[]\n",
    "    validationAccuracyListRow=[]\n",
    "    testAccuracyListRow=[]\n",
    "    \n",
    "    for colInd in range(len(C_lambda)):\n",
    "        \n",
    "        # Get predicted labels for each set of data\n",
    "        TR_TEST_OUT  = GetValTest(trainingPHIList[rowInd],weightList[rowInd][colInd])\n",
    "        VAL_TEST_OUT = GetValTest(validationPHIList[rowInd],weightList[rowInd][colInd])\n",
    "        TEST_OUT     = GetValTest(testPHIList[rowInd],weightList[rowInd][colInd])\n",
    "\n",
    "        # Get training accuracy and ERMS for each data set based on the target and its predicted labels\n",
    "        trainingAccuracyListRow.append(str(GetErms(TR_TEST_OUT,TrainingTarget)))\n",
    "        validationAccuracyListRow.append(str(GetErms(VAL_TEST_OUT,ValDataAct)))\n",
    "        testAccuracyListRow.append(str(GetErms(TEST_OUT,TestDataAct)))\n",
    "        \n",
    "    trainingAccuracyList.append(trainingAccuracyListRow)\n",
    "    validationAccuracyList.append(validationAccuracyListRow)\n",
    "    testAccuracyList.append(testAccuracyListRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBITname      = damirtha\n",
      "Person Number = 50291137\n",
      "----------------------------------------------------\n",
      "------------------LeToR Data------------------------\n",
      "----------------------------------------------------\n",
      "-------Closed Form with Radial Basis Function-------\n",
      "----------------------------------------------------\n",
      "M = 1 \n",
      "Lambda = 0\n",
      "E_rms Training   = 2.3920829738654725\n",
      "E_rms Validation = 2.4013799095156103\n",
      "E_rms Testing    = 2.3361548980569\n",
      "M = 1 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 2.296036160321233\n",
      "E_rms Validation = 2.3051336583468687\n",
      "E_rms Testing    = 2.2411745658094824\n",
      "M = 1 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 2.1157284532485323\n",
      "E_rms Validation = 2.124414745783125\n",
      "E_rms Testing    = 2.0631403652583797\n",
      "M = 1 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 1.5944321490991478\n",
      "E_rms Validation = 1.6015042221772522\n",
      "E_rms Testing    = 1.551566625326623\n",
      "M = 1 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 0.7892438060864891\n",
      "E_rms Validation = 0.789285995008331\n",
      "E_rms Testing    = 0.7944219731462827\n",
      "M = 1 \n",
      "Lambda = 1\n",
      "E_rms Training   = 0.5998433803350005\n",
      "E_rms Validation = 0.5861362613762499\n",
      "E_rms Testing    = 0.6928902316948181\n",
      "M = 1 \n",
      "Lambda = 10\n",
      "E_rms Training   = 0.6426212943124214\n",
      "E_rms Validation = 0.6281326595734317\n",
      "E_rms Testing    = 0.740746596184622\n",
      "M = 5 \n",
      "Lambda = 0\n",
      "E_rms Training   = 26.679526284542927\n",
      "E_rms Validation = 26.845205601340858\n",
      "E_rms Testing    = 26.951171646852448\n",
      "M = 5 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 25.623873822302812\n",
      "E_rms Validation = 25.783103915142256\n",
      "E_rms Testing    = 25.884301735794125\n",
      "M = 5 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 23.63516214251035\n",
      "E_rms Validation = 23.78224158423442\n",
      "E_rms Testing    = 23.874480295208198\n",
      "M = 5 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 17.804630745728353\n",
      "E_rms Validation = 17.91606688482654\n",
      "E_rms Testing    = 17.98230876358698\n",
      "M = 5 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 7.881080125637367\n",
      "E_rms Validation = 7.931486494036627\n",
      "E_rms Testing    = 7.956577764513237\n",
      "M = 5 \n",
      "Lambda = 1\n",
      "E_rms Training   = 0.6528384017557293\n",
      "E_rms Validation = 0.6426054145403411\n",
      "E_rms Testing    = 0.7361729617287579\n",
      "M = 5 \n",
      "Lambda = 10\n",
      "E_rms Training   = 0.6426098817204529\n",
      "E_rms Validation = 0.6281213449272964\n",
      "E_rms Testing    = 0.7407344242701991\n",
      "M = 10 \n",
      "Lambda = 0\n",
      "E_rms Training   = 32.13031915920666\n",
      "E_rms Validation = 31.21899929951798\n",
      "E_rms Testing    = 31.91312567961253\n",
      "M = 10 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 30.94499970334297\n",
      "E_rms Validation = 30.07754786434798\n",
      "E_rms Testing    = 30.732677127258466\n",
      "M = 10 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 28.616885463797463\n",
      "E_rms Validation = 27.82824428513862\n",
      "E_rms Testing    = 28.414646355217304\n",
      "M = 10 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 21.522900345398536\n",
      "E_rms Validation = 20.95075584748995\n",
      "E_rms Testing    = 21.356653027395947\n",
      "M = 10 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 9.37916889778687\n",
      "E_rms Validation = 9.146830817271681\n",
      "E_rms Testing    = 9.290010984485235\n",
      "M = 10 \n",
      "Lambda = 1\n",
      "E_rms Training   = 0.655702275445678\n",
      "E_rms Validation = 0.6424449597290245\n",
      "E_rms Testing    = 0.726987702311135\n",
      "M = 10 \n",
      "Lambda = 10\n",
      "E_rms Training   = 0.6427041964712943\n",
      "E_rms Validation = 0.6282146054394723\n",
      "E_rms Testing    = 0.740835998860152\n",
      "M = 50 \n",
      "Lambda = 0\n",
      "E_rms Training   = 35.66494945949027\n",
      "E_rms Validation = 35.52100810609604\n",
      "E_rms Testing    = 36.539660898509844\n",
      "M = 50 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 33.687534149092066\n",
      "E_rms Validation = 33.66890940965512\n",
      "E_rms Testing    = 34.4711175672933\n",
      "M = 50 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 30.852972026767578\n",
      "E_rms Validation = 30.801153761011633\n",
      "E_rms Testing    = 31.44309591893989\n",
      "M = 50 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 22.86153441747522\n",
      "E_rms Validation = 22.776539177539824\n",
      "E_rms Testing    = 23.132032089721577\n",
      "M = 50 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 9.874972788291002\n",
      "E_rms Validation = 9.814825491144877\n",
      "E_rms Testing    = 9.921992981377471\n",
      "M = 50 \n",
      "Lambda = 1\n",
      "E_rms Training   = 0.6512398466872059\n",
      "E_rms Validation = 0.649173265929472\n",
      "E_rms Testing    = 0.7231911574107996\n",
      "M = 50 \n",
      "Lambda = 10\n",
      "E_rms Training   = 0.6427341863433508\n",
      "E_rms Validation = 0.6282441411460612\n",
      "E_rms Testing    = 0.7408692415468081\n",
      "M = 100 \n",
      "Lambda = 0\n",
      "E_rms Training   = 38.01936694686845\n",
      "E_rms Validation = 37.92096839444828\n",
      "E_rms Testing    = 39.346975748984285\n",
      "M = 100 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 32.849199773723775\n",
      "E_rms Validation = 32.54032852363336\n",
      "E_rms Testing    = 33.75567528657658\n",
      "M = 100 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 30.18273992197481\n",
      "E_rms Validation = 29.9218377335551\n",
      "E_rms Testing    = 31.094672013254524\n",
      "M = 100 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 22.516179570196613\n",
      "E_rms Validation = 22.371363581833574\n",
      "E_rms Testing    = 23.191227357557704\n",
      "M = 100 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 9.720463290089555\n",
      "E_rms Validation = 9.675452168063394\n",
      "E_rms Testing    = 9.966024843321629\n",
      "M = 100 \n",
      "Lambda = 1\n",
      "E_rms Training   = 0.661372238778231\n",
      "E_rms Validation = 0.6638898503893774\n",
      "E_rms Testing    = 0.7418074349986556\n",
      "M = 100 \n",
      "Lambda = 10\n",
      "E_rms Training   = 0.6427022843487612\n",
      "E_rms Validation = 0.6282124333375447\n",
      "E_rms Testing    = 0.7408362108374817\n",
      "M = 200 \n",
      "Lambda = 0\n",
      "E_rms Training   = 41.4108900250972\n",
      "E_rms Validation = 41.66248927891499\n",
      "E_rms Testing    = 43.398530664196386\n",
      "M = 200 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 31.365665985633193\n",
      "E_rms Validation = 30.734908468791577\n",
      "E_rms Testing    = 31.939295967681865\n",
      "M = 200 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 28.173381410666494\n",
      "E_rms Validation = 27.6155455828191\n",
      "E_rms Testing    = 28.759982708183376\n",
      "M = 200 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 20.606315782879115\n",
      "E_rms Validation = 20.241304447534826\n",
      "E_rms Testing    = 21.104114317180297\n",
      "M = 200 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 8.9331734997099\n",
      "E_rms Validation = 8.8027260201016\n",
      "E_rms Testing    = 9.146008833526695\n",
      "M = 200 \n",
      "Lambda = 1\n",
      "E_rms Training   = 0.7708048364513015\n",
      "E_rms Validation = 0.7683867132296816\n",
      "E_rms Testing    = 0.8624952468370822\n",
      "M = 200 \n",
      "Lambda = 10\n",
      "E_rms Training   = 0.6424409491422748\n",
      "E_rms Validation = 0.6279526301544965\n",
      "E_rms Testing    = 0.740557624865796\n",
      "M = 400 \n",
      "Lambda = 0\n",
      "E_rms Training   = 2.376588065024596e+96\n",
      "E_rms Validation = 2.3777552286151052e+96\n",
      "E_rms Testing    = 2.374608221417802e+96\n",
      "M = 400 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 2.380746331373834e+96\n",
      "E_rms Validation = 2.3819154908813595e+96\n",
      "E_rms Testing    = 2.3787630327086925e+96\n",
      "M = 400 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 2.476660158039786e+96\n",
      "E_rms Validation = 2.4778763236464884e+96\n",
      "E_rms Testing    = 2.474596976424922e+96\n",
      "M = 400 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 2.88654756077635e+96\n",
      "E_rms Validation = 2.8879646100635294e+96\n",
      "E_rms Testing    = 2.884142999032061e+96\n",
      "M = 400 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 4.5494319247214765e+96\n",
      "E_rms Validation = 4.551663551394765e+96\n",
      "E_rms Testing    = 4.545642484930962e+96\n",
      "M = 400 \n",
      "Lambda = 1\n",
      "E_rms Training   = 2.2916724619606673e+97\n",
      "E_rms Validation = 2.292793534832715e+97\n",
      "E_rms Testing    = 2.2897642173229196e+97\n",
      "M = 400 \n",
      "Lambda = 10\n",
      "E_rms Training   = 1.4318123538787234e+106\n",
      "E_rms Validation = 1.4324912734674632e+106\n",
      "E_rms Testing    = 1.4306243553215007e+106\n",
      "\n",
      "----------------------------------------------------\n",
      "Validation results\n",
      "Best M for this model = 1\n",
      "Best Lambda for this model = 1\n",
      "\n",
      "----------------------------------------------------\n",
      "Final test results\n",
      "Accuracy, E_rms Testing    = 70.23416175836805,0.6928902316948181\n"
     ]
    }
   ],
   "source": [
    "print ('UBITname      = damirtha')\n",
    "print ('Person Number = 50291137')\n",
    "print ('----------------------------------------------------')\n",
    "print (\"------------------LeToR Data------------------------\")\n",
    "print ('----------------------------------------------------')\n",
    "print (\"-------Closed Form with Radial Basis Function-------\")\n",
    "print ('----------------------------------------------------')\n",
    "bestERMS=100\n",
    "bestM=0\n",
    "bestLambda=0\n",
    "\n",
    "for rowInd in range(len(M)):\n",
    "    for colInd in range(len(C_lambda)):\n",
    "        \n",
    "        print (\"M = \"+str(M[rowInd])+\" \\nLambda = \"+str(C_lambda[colInd]))\n",
    "        print (\"E_rms Training   = \" + str(float(trainingAccuracyList[rowInd][colInd].split(',')[1])))\n",
    "        print (\"E_rms Validation = \" + str(float(validationAccuracyList[rowInd][colInd].split(',')[1])))\n",
    "        if float(validationAccuracyList[rowInd][colInd].split(',')[1]) < bestERMS:\n",
    "            bestERMS=float(validationAccuracyList[rowInd][colInd].split(',')[1])\n",
    "            bestM=M[rowInd]\n",
    "            bestLambda=C_lambda[colInd]\n",
    "        print (\"E_rms Testing    = \" + str(float(testAccuracyList[rowInd][colInd].split(',')[1])))\n",
    "        \n",
    "print ('\\n----------------------------------------------------')\n",
    "print ('Validation results')\n",
    "print(\"Best M for this model = \"+str(bestM))\n",
    "print(\"Best Lambda for this model = \"+str(bestLambda))\n",
    "print ('\\n----------------------------------------------------')\n",
    "print ('Final test results')\n",
    "print (\"Accuracy, E_rms Testing    = \"+testAccuracyList[M.index(bestM)][C_lambda.index(bestLambda)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent solution for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "--------------Please Wait for 2 mins!----------------\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print ('----------------------------------------------------')\n",
    "print ('--------------Please Wait for 2 mins!----------------')\n",
    "print ('----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientWeightList=[]\n",
    "\n",
    "for rowInd in range(len(M)):\n",
    "    gradientWeightListRow=[]\n",
    "    for colInd in range(len(C_lambda)):\n",
    "        # Blowing up value of weights obtained from closed form solution, to be trained and learnt again\n",
    "        W_Now        = np.dot(220, weightList[rowInd][colInd])\n",
    "\n",
    "        # lambda, regularization paramter for gradient descent algorithm, used to prevent overfitting\n",
    "        La           = 2\n",
    "\n",
    "        # learning rate to set how gradient descent should converge, very low value may lead to slow convergence, \n",
    "        # high value may lead to algorithm not converging at all\n",
    "        learningRate = 0.01\n",
    "\n",
    "        # Initializing lists\n",
    "        L_Erms_Val   = []\n",
    "        L_Erms_TR    = []\n",
    "        L_Erms_Test  = []\n",
    "        W_Mat        = []\n",
    "\n",
    "        # For first 400 samples in the data\n",
    "        for i in range(0,400):\n",
    "\n",
    "            # Compute the partial derivative of the cost function with respect to feature each feature f without regulirization\n",
    "            Delta_E_D     = -np.dot((TrainingTarget[i] - np.dot(np.transpose(W_Now),trainingPHIList[rowInd][i])),trainingPHIList[rowInd][i])\n",
    "\n",
    "            # Compute lambda*weights (partitial derivative of (1/2)lambda*W^2 added in the cost function)\n",
    "            La_Delta_E_W  = np.dot(C_lambda[colInd],W_Now)\n",
    "\n",
    "            # Adding reguirization to the partial derivative\n",
    "            Delta_E       = np.add(Delta_E_D,La_Delta_E_W)   \n",
    "\n",
    "            # Calculating Wf-ndE/dWf for all features, where n is eta, W is weights for each feature f. This is the new value of W obtained through gradient descent\n",
    "            Delta_W       = -np.dot(learningRate,Delta_E)\n",
    "            W_T_Next      = W_Now + Delta_W\n",
    "            W_Now         = W_T_Next\n",
    "        gradientWeightListRow.append(W_T_Next)\n",
    "    gradientWeightList.append(gradientWeightListRow)\n",
    "    \n",
    "        # Function calls to get predicted labels using the learned weights for each data set\n",
    "        # and getting training accuracy and ERMS for each data set based on the target and its predicted labels\n",
    "# Function calls to get predicted labels using the learned weights for each data set\n",
    "trainingAccuracyList=[]\n",
    "validationAccuracyList=[]\n",
    "testAccuracyList=[]\n",
    "\n",
    "for rowInd in range(len(M)):\n",
    "    trainingAccuracyListRow=[]\n",
    "    validationAccuracyListRow=[]\n",
    "    testAccuracyListRow=[]\n",
    "    \n",
    "    for colInd in range(len(C_lambda)):\n",
    "        TR_TEST_OUT  = GetValTest(trainingPHIList[rowInd],gradientWeightList[rowInd][colInd])\n",
    "        VAL_TEST_OUT = GetValTest(validationPHIList[rowInd],gradientWeightList[rowInd][colInd])\n",
    "        TEST_OUT     = GetValTest(testPHIList[rowInd],gradientWeightList[rowInd][colInd])\n",
    "\n",
    "        # Get training accuracy and ERMS for each data set based on the target and its predicted labels\n",
    "        trainingAccuracyListRow.append(str(GetErms(TR_TEST_OUT,TrainingTarget)))\n",
    "        validationAccuracyListRow.append(str(GetErms(VAL_TEST_OUT,ValDataAct)))\n",
    "        testAccuracyListRow.append(str(GetErms(TEST_OUT,TestDataAct)))\n",
    "        \n",
    "    trainingAccuracyList.append(trainingAccuracyListRow)\n",
    "    validationAccuracyList.append(validationAccuracyListRow)\n",
    "    testAccuracyList.append(testAccuracyListRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Gradient descent solution-------\n",
      "M = 1 \n",
      "Lambda = 0\n",
      "E_rms Training   = 2.3920829738654725\n",
      "E_rms Validation = 2.4013799095156103\n",
      "E_rms Testing    = 2.3361548980569\n",
      "M = 1 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 2.296036160321233\n",
      "E_rms Validation = 2.3051336583468687\n",
      "E_rms Testing    = 2.2411745658094824\n",
      "M = 1 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 2.1157284532485323\n",
      "E_rms Validation = 2.124414745783125\n",
      "E_rms Testing    = 2.0631403652583797\n",
      "M = 1 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 1.5944321490991478\n",
      "E_rms Validation = 1.6015042221772522\n",
      "E_rms Testing    = 1.551566625326623\n",
      "M = 1 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 0.7892438060864891\n",
      "E_rms Validation = 0.789285995008331\n",
      "E_rms Testing    = 0.7944219731462827\n",
      "M = 1 \n",
      "Lambda = 1\n",
      "E_rms Training   = 0.5998433803350005\n",
      "E_rms Validation = 0.5861362613762499\n",
      "E_rms Testing    = 0.6928902316948181\n",
      "M = 1 \n",
      "Lambda = 10\n",
      "E_rms Training   = 0.6426212943124214\n",
      "E_rms Validation = 0.6281326595734317\n",
      "E_rms Testing    = 0.740746596184622\n",
      "M = 5 \n",
      "Lambda = 0\n",
      "E_rms Training   = 26.679526284542927\n",
      "E_rms Validation = 26.845205601340858\n",
      "E_rms Testing    = 26.951171646852448\n",
      "M = 5 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 25.623873822302812\n",
      "E_rms Validation = 25.783103915142256\n",
      "E_rms Testing    = 25.884301735794125\n",
      "M = 5 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 23.63516214251035\n",
      "E_rms Validation = 23.78224158423442\n",
      "E_rms Testing    = 23.874480295208198\n",
      "M = 5 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 17.804630745728353\n",
      "E_rms Validation = 17.91606688482654\n",
      "E_rms Testing    = 17.98230876358698\n",
      "M = 5 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 7.881080125637367\n",
      "E_rms Validation = 7.931486494036627\n",
      "E_rms Testing    = 7.956577764513237\n",
      "M = 5 \n",
      "Lambda = 1\n",
      "E_rms Training   = 0.6528384017557293\n",
      "E_rms Validation = 0.6426054145403411\n",
      "E_rms Testing    = 0.7361729617287579\n",
      "M = 5 \n",
      "Lambda = 10\n",
      "E_rms Training   = 0.6426098817204529\n",
      "E_rms Validation = 0.6281213449272964\n",
      "E_rms Testing    = 0.7407344242701991\n",
      "M = 10 \n",
      "Lambda = 0\n",
      "E_rms Training   = 32.13031915920666\n",
      "E_rms Validation = 31.21899929951798\n",
      "E_rms Testing    = 31.91312567961253\n",
      "M = 10 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 30.94499970334297\n",
      "E_rms Validation = 30.07754786434798\n",
      "E_rms Testing    = 30.732677127258466\n",
      "M = 10 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 28.616885463797463\n",
      "E_rms Validation = 27.82824428513862\n",
      "E_rms Testing    = 28.414646355217304\n",
      "M = 10 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 21.522900345398536\n",
      "E_rms Validation = 20.95075584748995\n",
      "E_rms Testing    = 21.356653027395947\n",
      "M = 10 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 9.37916889778687\n",
      "E_rms Validation = 9.146830817271681\n",
      "E_rms Testing    = 9.290010984485235\n",
      "M = 10 \n",
      "Lambda = 1\n",
      "E_rms Training   = 0.655702275445678\n",
      "E_rms Validation = 0.6424449597290245\n",
      "E_rms Testing    = 0.726987702311135\n",
      "M = 10 \n",
      "Lambda = 10\n",
      "E_rms Training   = 0.6427041964712943\n",
      "E_rms Validation = 0.6282146054394723\n",
      "E_rms Testing    = 0.740835998860152\n",
      "M = 50 \n",
      "Lambda = 0\n",
      "E_rms Training   = 35.66494945949027\n",
      "E_rms Validation = 35.52100810609604\n",
      "E_rms Testing    = 36.539660898509844\n",
      "M = 50 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 33.687534149092066\n",
      "E_rms Validation = 33.66890940965512\n",
      "E_rms Testing    = 34.4711175672933\n",
      "M = 50 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 30.852972026767578\n",
      "E_rms Validation = 30.801153761011633\n",
      "E_rms Testing    = 31.44309591893989\n",
      "M = 50 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 22.86153441747522\n",
      "E_rms Validation = 22.776539177539824\n",
      "E_rms Testing    = 23.132032089721577\n",
      "M = 50 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 9.874972788291002\n",
      "E_rms Validation = 9.814825491144877\n",
      "E_rms Testing    = 9.921992981377471\n",
      "M = 50 \n",
      "Lambda = 1\n",
      "E_rms Training   = 0.6512398466872059\n",
      "E_rms Validation = 0.649173265929472\n",
      "E_rms Testing    = 0.7231911574107996\n",
      "M = 50 \n",
      "Lambda = 10\n",
      "E_rms Training   = 0.6427341863433508\n",
      "E_rms Validation = 0.6282441411460612\n",
      "E_rms Testing    = 0.7408692415468081\n",
      "M = 100 \n",
      "Lambda = 0\n",
      "E_rms Training   = 38.01936694686845\n",
      "E_rms Validation = 37.92096839444828\n",
      "E_rms Testing    = 39.346975748984285\n",
      "M = 100 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 32.849199773723775\n",
      "E_rms Validation = 32.54032852363336\n",
      "E_rms Testing    = 33.75567528657658\n",
      "M = 100 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 30.18273992197481\n",
      "E_rms Validation = 29.9218377335551\n",
      "E_rms Testing    = 31.094672013254524\n",
      "M = 100 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 22.516179570196613\n",
      "E_rms Validation = 22.371363581833574\n",
      "E_rms Testing    = 23.191227357557704\n",
      "M = 100 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 9.720463290089555\n",
      "E_rms Validation = 9.675452168063394\n",
      "E_rms Testing    = 9.966024843321629\n",
      "M = 100 \n",
      "Lambda = 1\n",
      "E_rms Training   = 0.661372238778231\n",
      "E_rms Validation = 0.6638898503893774\n",
      "E_rms Testing    = 0.7418074349986556\n",
      "M = 100 \n",
      "Lambda = 10\n",
      "E_rms Training   = 0.6427022843487612\n",
      "E_rms Validation = 0.6282124333375447\n",
      "E_rms Testing    = 0.7408362108374817\n",
      "M = 200 \n",
      "Lambda = 0\n",
      "E_rms Training   = 41.4108900250972\n",
      "E_rms Validation = 41.66248927891499\n",
      "E_rms Testing    = 43.398530664196386\n",
      "M = 200 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 31.365665985633193\n",
      "E_rms Validation = 30.734908468791577\n",
      "E_rms Testing    = 31.939295967681865\n",
      "M = 200 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 28.173381410666494\n",
      "E_rms Validation = 27.6155455828191\n",
      "E_rms Testing    = 28.759982708183376\n",
      "M = 200 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 20.606315782879115\n",
      "E_rms Validation = 20.241304447534826\n",
      "E_rms Testing    = 21.104114317180297\n",
      "M = 200 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 8.9331734997099\n",
      "E_rms Validation = 8.8027260201016\n",
      "E_rms Testing    = 9.146008833526695\n",
      "M = 200 \n",
      "Lambda = 1\n",
      "E_rms Training   = 0.7708048364513015\n",
      "E_rms Validation = 0.7683867132296816\n",
      "E_rms Testing    = 0.8624952468370822\n",
      "M = 200 \n",
      "Lambda = 10\n",
      "E_rms Training   = 0.6424409491422748\n",
      "E_rms Validation = 0.6279526301544965\n",
      "E_rms Testing    = 0.740557624865796\n",
      "M = 400 \n",
      "Lambda = 0\n",
      "E_rms Training   = 2.376588065024596e+96\n",
      "E_rms Validation = 2.3777552286151052e+96\n",
      "E_rms Testing    = 2.374608221417802e+96\n",
      "M = 400 \n",
      "Lambda = 0.01\n",
      "E_rms Training   = 2.380746331373834e+96\n",
      "E_rms Validation = 2.3819154908813595e+96\n",
      "E_rms Testing    = 2.3787630327086925e+96\n",
      "M = 400 \n",
      "Lambda = 0.03\n",
      "E_rms Training   = 2.476660158039786e+96\n",
      "E_rms Validation = 2.4778763236464884e+96\n",
      "E_rms Testing    = 2.474596976424922e+96\n",
      "M = 400 \n",
      "Lambda = 0.1\n",
      "E_rms Training   = 2.88654756077635e+96\n",
      "E_rms Validation = 2.8879646100635294e+96\n",
      "E_rms Testing    = 2.884142999032061e+96\n",
      "M = 400 \n",
      "Lambda = 0.3\n",
      "E_rms Training   = 4.5494319247214765e+96\n",
      "E_rms Validation = 4.551663551394765e+96\n",
      "E_rms Testing    = 4.545642484930962e+96\n",
      "M = 400 \n",
      "Lambda = 1\n",
      "E_rms Training   = 2.2916724619606673e+97\n",
      "E_rms Validation = 2.292793534832715e+97\n",
      "E_rms Testing    = 2.2897642173229196e+97\n",
      "M = 400 \n",
      "Lambda = 10\n",
      "E_rms Training   = 1.4318123538787234e+106\n",
      "E_rms Validation = 1.4324912734674632e+106\n",
      "E_rms Testing    = 1.4306243553215007e+106\n",
      "\n",
      "----------------------------------------------------\n",
      "Validation results\n",
      "Best M for this model = 1\n",
      "Best Lambda for this model = 1\n",
      "\n",
      "----------------------------------------------------\n",
      "Final test results\n",
      "Accuracy, E_rms Testing    = 70.23416175836805,0.6928902316948181\n"
     ]
    }
   ],
   "source": [
    "print (\"-------Gradient descent solution-------\")\n",
    "bestERMS=100\n",
    "bestM=0\n",
    "bestLambda=0\n",
    "\n",
    "for rowInd in range(len(M)):\n",
    "    for colInd in range(len(C_lambda)):\n",
    "        \n",
    "        print (\"M = \"+str(M[rowInd])+\" \\nLambda = \"+str(C_lambda[colInd]))\n",
    "        print (\"E_rms Training   = \" + str(float(trainingAccuracyList[rowInd][colInd].split(',')[1])))\n",
    "        print (\"E_rms Validation = \" + str(float(validationAccuracyList[rowInd][colInd].split(',')[1])))\n",
    "        if float(validationAccuracyList[rowInd][colInd].split(',')[1]) < bestERMS:\n",
    "            bestERMS=float(validationAccuracyList[rowInd][colInd].split(',')[1])\n",
    "            bestM=M[rowInd]\n",
    "            bestLambda=C_lambda[colInd]\n",
    "        print (\"E_rms Testing    = \" + str(float(testAccuracyList[rowInd][colInd].split(',')[1])))\n",
    "        \n",
    "print ('\\n----------------------------------------------------')\n",
    "print ('Validation results')\n",
    "print(\"Best M for this model = \"+str(bestM))\n",
    "print(\"Best Lambda for this model = \"+str(bestLambda))\n",
    "print ('\\n----------------------------------------------------')\n",
    "print ('Final test results')\n",
    "print (\"Accuracy, E_rms Testing    = \"+testAccuracyList[M.index(bestM)][C_lambda.index(bestLambda)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
